{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_segregation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bprtnoAeEzIi"
      },
      "source": [
        "#shuffling the data\r\n",
        "import random \r\n",
        "\r\n",
        "random.seed(33)\r\n",
        "random.shuffle(data)\r\n",
        "random.shuffle(data1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSCWpE9WFA42"
      },
      "source": [
        "# creating X and y from data list\r\n",
        "\r\n",
        "def extract_features_and_labels(data):\r\n",
        "    X = []\r\n",
        "    y = []\r\n",
        "    for features, labels in data:\r\n",
        "        X.append(features)\r\n",
        "        y.append(labels)\r\n",
        "\r\n",
        "    # converting into numpy arrays\r\n",
        "    X = np.array(X).reshape(-1,IMAGE_HEIGHT,IMAGE_WIDTH,3)\r\n",
        "    y = np.array(y)\r\n",
        "\r\n",
        "    return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh0OEK3WFDmG"
      },
      "source": [
        "#creating img and audio lists\r\n",
        "\r\n",
        "X_img,y_img = extract_features_and_labels(data_img)\r\n",
        "X_aud,y_aud = extract_features_and_labels(data_aud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcs62jttFJXU"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# segregating the training and test image data\r\n",
        "X_train_img,X_test_img,y_train_img,y_test_img = train_test_split(X_img,y_img,test_size=0.1) # 0.1 test to train split \r\n",
        "\r\n",
        "# segregating the training and test audio data\r\n",
        "X_train_aud,X_test_aud,y_train_aud,y_test_aud = train_test_split(X_aud,y_aud,test_size=0.1) # 0.1 test to train split "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rubCM0GFx4t"
      },
      "source": [
        "print('Shape of X_train_img:' + str(X_train_img.shape))\r\n",
        "print('Shape of y_train_img:' + str(y_train_img.shape))\r\n",
        "print('Shape of X_test_img:' + str(X_test_img.shape))\r\n",
        "print('Shape of y_test_img:' + str(y_test_img.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b8qd5cZG4ni"
      },
      "source": [
        "print('Shape of X_train_aud:' + str(X_train_aud.shape))\r\n",
        "print('Shape of y_train_aud:' + str(y_train_aud.shape))\r\n",
        "print('Shape of X_test_aud:' + str(X_test_aud.shape))\r\n",
        "print('Shape of y_test_aud:' + str(y_test_aud.shape))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}