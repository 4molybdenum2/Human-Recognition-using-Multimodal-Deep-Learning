{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "execute_multimodal.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "minMWXytkKEb"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import shutil\r\n",
        "import cv2\r\n",
        "import sys\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import wave\r\n",
        "import pylab\r\n",
        "from pathlib import Path\r\n",
        "from scipy import signal\r\n",
        "from scipy.io import wavfile\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import itertools\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import datasets, layers, models\r\n",
        "from keras.layers import Add, Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D , Dropout , Concatenate, Reshape , Lambda\r\n",
        "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Bidirectional,LSTM,Reshape\r\n",
        "from keras.models import Model\r\n",
        "from keras.losses import categorical_crossentropy\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.regularizers import l2\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.metrics import Recall,Precision\r\n",
        "from keras.callbacks import ModelCheckpoint\r\n",
        "from keras.initializers import glorot_uniform\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxyAETHZilb4",
        "outputId": "ebd13593-0935-49b3-bc9c-1330daf99526"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JfVvG6PCJ34"
      },
      "source": [
        "import extract_data\r\n",
        "import create_multimodal_pairs\r\n",
        "import architectures\r\n",
        "import siamese"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUWqwdMTfjk-"
      },
      "source": [
        "# Declare constants\r\n",
        "\r\n",
        "BATCH_SIZE = 64\r\n",
        "N_CHANNELS = 3\r\n",
        "N_CLASSES = 20\r\n",
        "\r\n",
        "IMAGE_HEIGHT = 128\r\n",
        "IMAGE_WIDTH = 128\r\n",
        "IMG_SHAPE = (IMAGE_HEIGHT,IMAGE_WIDTH,N_CHANNELS)\r\n",
        "\r\n",
        "AUD_HEIGHT = 128\r\n",
        "AUD_WIDTH = 128\r\n",
        "AUD_SHAPE = (AUD_HEIGHT,AUD_WIDTH,N_CHANNELS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYZbSHvsECPR"
      },
      "source": [
        "data_dir =  #set path to the folder containing subfolders containing your images \r\n",
        "\r\n",
        "#list of subfolders which denote different classes of your dataset\r\n",
        "categories = os.listdir(data_dir)\r\n",
        "\r\n",
        "data_img = []\r\n",
        "categorical_index_img = [] #to keep track of which class is mapped to which index\r\n",
        "\r\n",
        "data_img,categorical_index_img = extract_data.create_data(data_dir,categories,data_img,categorical_index_img,IMAGE_HEIGHT,IMAGE_WIDTH)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wZend0cEJJC"
      },
      "source": [
        "data_dir =#set path to the folder containing subfolders containing the audio spectogram images\r\n",
        "\r\n",
        "#list of subfolders which denote different classes of your dataset\r\n",
        "categories = os.listdir(data_dir)\r\n",
        "\r\n",
        "data_aud = []\r\n",
        "categorical_index_aud = []\r\n",
        "\r\n",
        "data_aud,categorical_index_aud = extract_data.create_data(data_dir,categories,data_aud,categorical_index_aud,AUD_HEIGHT,AUD_WIDTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWKj8oFAFgwb"
      },
      "source": [
        "import random\r\n",
        "\r\n",
        "random.seed(33)\r\n",
        "random.shuffle(data_img)\r\n",
        "random.shuffle(data_aud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwgu3M4QEgpN"
      },
      "source": [
        "# creating X and y from data list\r\n",
        "\r\n",
        "X_img,y_img = extract_data.extract_features_and_labels(data_img)\r\n",
        "X_aud,y_aud = extract_data.extract_features_and_labels(data_aud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sa0ZAFjJQlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41338738-c07d-46d6-aac5-5e36ae9db61d"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# segregating the training and test image data\r\n",
        "X_train_img,X_test_img,y_train_img,y_test_img = train_test_split(X_img,y_img,test_size=0.1) # 0.1 test to train split \r\n",
        "\r\n",
        "# segregating the training and test audio data\r\n",
        "X_train_aud,X_test_aud,y_train_aud,y_test_aud = train_test_split(X_aud,y_aud,test_size=0.1) # 0.1 test to train split "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train:(587, 128, 128, 3)\n",
            "Shape of y_train:(587,)\n",
            "Shape of X_test:(66, 128, 128, 3)\n",
            "Shape of y_test:(66,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6F9lvaMIQwc"
      },
      "source": [
        "# create pairs from training data\r\n",
        "\r\n",
        "# to define the same list of classes\r\n",
        "same_class_list1 = []\r\n",
        "same_class_list2 = []\r\n",
        "img_a_train,aud_a_train,img_b_train,aud_b_train,labels_train  = create_multimodal_pairs.multimodal_data_generate(X_train_img , y_train_img , X_train_aud , y_train_aud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Clxwdz9cIZuT"
      },
      "source": [
        "# create pairs from test data\r\n",
        "\r\n",
        "# to define the same list of classes\r\n",
        "same_class_list1 = []\r\n",
        "same_class_list2 = [] \r\n",
        "img_a_test,aud_a_test,img_b_test,aud_b_test,labels_test  = create_multimodal_pairs.multimodal_data_generate(X_test_img , y_test_img , X_test_aud , y_test_aud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2m7ZwNw_PDD"
      },
      "source": [
        "# randomize the train data\r\n",
        "\r\n",
        "img_a_train,aud_a_train,img_b_train,aud_b_train,labels_train = extract_data.randomize_zip(img_a_train,aud_a_train,img_b_train,aud_b_train,labels_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nlcaR6GPrzY"
      },
      "source": [
        "# randomize the test data\r\n",
        "\r\n",
        "img_a_test,aud_a_test,img_b_test,aud_b_test,labels_test = extract_data.randomize_zip(img_a_test,aud_a_test,img_b_test,aud_b_test,labels_test )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdlH9rVNDdrm"
      },
      "source": [
        "input_dim_img = (IMAGE_HEIGHT,IMAGE_WIDTH,N_CHANNELS)\r\n",
        "input_dim_aud = (AUD_HEIGHT,AUD_WIDTH,N_CHANNELS)\r\n",
        "\r\n",
        "# final model train \r\n",
        "optimizer , model = siamese.siamese_network(input_dim_img , input_dim_aud)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5kt9Rj8AQuh"
      },
      "source": [
        "weight_dir = #set a weights directory\r\n",
        "if not os.path.exists(weight_dir):\r\n",
        "    os.mkdir(weight_dir)\r\n",
        "    \r\n",
        "#checkpoints for best weights in terms of validation accuracy\r\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=weight_dir+'/checkpoint-{epoch:02d}-{val_loss:.4f}.hdf5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_accuracy',\r\n",
        "    mode='max',\r\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIB-NYoRlVLh"
      },
      "source": [
        "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\r\n",
        "model.fit([np.asarray(img_a_train),np.asarray(aud_a_train),np.asarray(img_b_train),np.asarray(aud_b_train)], np.asarray(labels_train) ,validation_split=0.2, batch_size = BATCH_SIZE , verbose = 1, epochs = 30 , callbacks = checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}